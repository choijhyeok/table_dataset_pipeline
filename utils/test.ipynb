{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from blob_controller import blob_controller\n",
    "import os\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import mimetypes\n",
    "import tempfile\n",
    "from pathlib import Path\n",
    "\n",
    "from azure.core.exceptions import ResourceExistsError, ResourceNotFoundError\n",
    "\n",
    "from azure.storage.blob import (\n",
    "    BlobServiceClient,\n",
    "    ContainerClient,\n",
    "    BlobClient,\n",
    "    generate_blob_sas,\n",
    "    BlobSasPermissions,\n",
    "    ContentSettings,\n",
    ")\n",
    "import fitz\n",
    "\n",
    "class blob_controller:\n",
    "    def __init__(self, conn: str, container: str):\n",
    "        if not conn:\n",
    "            raise ValueError(\"Azure connection stringì´ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.\")\n",
    "        if not container or container.lower() != container:\n",
    "            raise ValueError(\"ì»¨í…Œì´ë„ˆ ì´ë¦„ì€ ì†Œë¬¸ìì—¬ì•¼ í•©ë‹ˆë‹¤. (ì˜ˆ: 'meritz-data')\")\n",
    "\n",
    "        self.conn = conn\n",
    "        self.container = container\n",
    "        self.blob_service = BlobServiceClient.from_connection_string(conn)\n",
    "        self.container_client = self.blob_service.get_container_client(container)\n",
    "\n",
    "        # ì»¨í…Œì´ë„ˆ ì—†ìœ¼ë©´ ìƒì„±, ìˆìœ¼ë©´ ë¬´ì‹œ\n",
    "        self.ensure_container_exists()\n",
    "\n",
    "    def ensure_container_exists(self):\n",
    "        try:\n",
    "            self.container_client.create_container()\n",
    "        except ResourceExistsError:\n",
    "            pass \n",
    "\n",
    "\n",
    "    def upload_pdf_to_blob(self, file_path: str) -> str:\n",
    "        \"\"\"\n",
    "        ë¡œì»¬ PDF íŒŒì¼ì„ ì—…ë¡œë“œ. blob_nameì„ ë„˜ê¸°ì§€ ì•Šìœ¼ë©´  basenameìœ¼ë¡œ ì—…ë¡œë“œ.\n",
    "        \"\"\"\n",
    "        name = os.path.basename(file_path)\n",
    "        blob_client: BlobClient = self.container_client.get_blob_client(name)\n",
    "        with open(file_path, \"rb\") as f:\n",
    "            blob_client.upload_blob(\n",
    "                f,\n",
    "                overwrite=True,\n",
    "                max_concurrency=3,\n",
    "                timeout=600,\n",
    "                content_settings=ContentSettings(content_type=\"application/pdf\"),\n",
    "            )\n",
    "        return name\n",
    "    \n",
    "    \n",
    "    def list_files(self):\n",
    "        \"\"\"\n",
    "        íŠ¹ì • prefix í•˜ìœ„ì˜ blob ëª©ë¡ ë°˜í™˜\n",
    "        \"\"\"\n",
    "        blobs = self.container_client.list_blobs()\n",
    "        file_list = [b.name for b in blobs]\n",
    "        return file_list\n",
    "    \n",
    "    \n",
    "    def download_to_temp(self, blob_name: str, tmp_dir: Path | str) -> Path:\n",
    "        \"\"\"\n",
    "        blob_name(ì»¨í…Œì´ë„ˆ ë‚´ ê²½ë¡œ)ì„ tmp_dirì— íŒŒì¼ë¡œ ì €ì¥í•˜ê³  ê·¸ ê²½ë¡œ(Path)ë¥¼ ë°˜í™˜.\n",
    "        tmp_dirì€ str ë˜ëŠ” Path ëª¨ë‘ í—ˆìš©.\n",
    "        \"\"\"\n",
    "        # str ì´ ë“¤ì–´ì™€ë„ Path ë¡œ ì •ê·œí™”\n",
    "        tmp_dir = Path(tmp_dir)\n",
    "        tmp_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        local_path = tmp_dir / Path(blob_name).name\n",
    "\n",
    "        bc: BlobClient = self.container_client.get_blob_client(blob_name)\n",
    "        try:\n",
    "            stream = bc.download_blob(max_concurrency=4)\n",
    "            with open(local_path, \"wb\") as f:\n",
    "                for chunk in stream.chunks():\n",
    "                    if chunk:\n",
    "                        f.write(chunk)\n",
    "        except ResourceNotFoundError:\n",
    "            raise FileNotFoundError(f\"Blob not found: {blob_name}\")\n",
    "\n",
    "        return local_path\n",
    "    \n",
    "    \n",
    "    \n",
    "    def open_pdf_from_blob_stream(self, blob_name: str):\n",
    "        \"\"\"\n",
    "        ë””ìŠ¤í¬ ì„ì‹œíŒŒì¼ ì—†ì´ Blobì„ ìŠ¤íŠ¸ë¦¬ë°ìœ¼ë¡œ ì½ì–´ ë©”ëª¨ë¦¬/ìŠ¤í’€ ë²„í¼ì— ì ì¬í•œ ë’¤,\n",
    "        fitz.open(stream=..., filetype=\"pdf\")ë¡œ ë°”ë¡œ ì—°ë‹¤.\n",
    "        - ì‘ì€/ì¤‘ê°„ ì‚¬ì´ì¦ˆ PDF: ë©”ëª¨ë¦¬ì—ì„œ ì²˜ë¦¬\n",
    "        - í° PDF: SpooledTemporaryFile ì´ ìë™ìœ¼ë¡œ ë””ìŠ¤í¬ë¡œ ìŠ¤í•„ì˜¤ë²„\n",
    "        \"\"\"\n",
    "        spooled = tempfile.SpooledTemporaryFile(max_size=64 * 1024 * 1024)  # 64MBê¹Œì§€ ë©”ëª¨ë¦¬, ì´ˆê³¼ ì‹œ ë””ìŠ¤í¬ ìŠ¤í•„ì˜¤ë²„\n",
    "        try:\n",
    "            blob_client = self.container_client.get_blob_client(blob_name)\n",
    "            stream = blob_client.download_blob(max_concurrency=4)\n",
    "            for chunk in stream.chunks():\n",
    "                if chunk:\n",
    "                    spooled.write(chunk)\n",
    "            spooled.seek(0)\n",
    "            data = spooled.read()\n",
    "            return fitz.open(stream=data, filetype=\"pdf\")\n",
    "        finally:\n",
    "            try:\n",
    "                spooled.close()\n",
    "            except Exception:\n",
    "                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'choiblob'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getenv(\"azure-blob-container-name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_bc = blob_controller(\n",
    "    conn = os.getenv(\"azure-blob-connection-string\"),\n",
    "    container = 'pdf'\n",
    ")\n",
    "\n",
    "img_bc = blob_controller(conn= os.getenv(\"azure-blob-connection-string\"), container='image')            # PNG\n",
    "md_bc = blob_controller(conn= os.getenv(\"azure-blob-connection-string\"), container='markdown')          # MD\n",
    "hist_bc = blob_controller(conn= os.getenv(\"azure-blob-connection-string\"), container='history')     \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import csv\n",
    "import io\n",
    "import os\n",
    "import time\n",
    "from datetime import datetime\n",
    "from tempfile import TemporaryDirectory\n",
    "import tempfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "blob_name = data_bc.list_files()[0]\n",
    "download_dir = \"./\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "blobs = data_bc.list_files()\n",
    "blob_name = blobs[0]\n",
    "\n",
    "\n",
    "doc = data_bc.open_pdf_from_blob_stream(blob_name)\n",
    "base = os.path.splitext(os.path.basename(blob_name))[0]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<pymupdf.table.Table object at 0x1073e79e0>]\n"
     ]
    }
   ],
   "source": [
    "# for i in range(len(doc)):\n",
    "i=7\n",
    "page = doc.load_page(i)\n",
    "\n",
    "\n",
    "table_finder = page.find_tables()\n",
    "tables = table_finder.tables if hasattr(table_finder, \"tables\") else []\n",
    "\n",
    "print(tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for /: 'str' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[38]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      8\u001b[39m png_name = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbase\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_p\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpage_num\u001b[38;5;250m \u001b[39m+\u001b[38;5;250m \u001b[39m\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_t\u001b[39m\u001b[38;5;132;01m{\u001b[39;00midx\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.png\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      9\u001b[39m md_name  = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbase\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_p\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpage_num\u001b[38;5;250m \u001b[39m+\u001b[38;5;250m \u001b[39m\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_t\u001b[39m\u001b[38;5;132;01m{\u001b[39;00midx\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.md\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m png_path = \u001b[43mdownload_dir\u001b[49m\u001b[43m \u001b[49m\u001b[43m/\u001b[49m\u001b[43m \u001b[49m\u001b[43mpng_name\u001b[49m\n\u001b[32m     11\u001b[39m md_path  = download_dir / md_name\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# PNG ìƒì„± (í‘œ bboxë§Œ clip)\u001b[39;00m\n",
      "\u001b[31mTypeError\u001b[39m: unsupported operand type(s) for /: 'str' and 'str'"
     ]
    }
   ],
   "source": [
    "page_num = i\n",
    "import logging\n",
    "\n",
    "for idx, t in enumerate(tables, start=1):\n",
    "    table_rect = fitz.Rect(t.bbox)\n",
    "\n",
    "    # íŒŒì¼ëª… (í‘œ ë‹¨ìœ„)\n",
    "    png_name = f\"{base}_p{page_num + 1}_t{idx}.png\"\n",
    "    md_name  = f\"{base}_p{page_num + 1}_t{idx}.md\"\n",
    "    png_path = download_dir / png_name\n",
    "    md_path  = download_dir / md_name\n",
    "\n",
    "    # PNG ìƒì„± (í‘œ bboxë§Œ clip)\n",
    "    try:\n",
    "        pix = page.get_pixmap(dpi=300, clip=table_rect)\n",
    "        pix.save(str(png_path))\n",
    "        png_ok = True\n",
    "    except Exception as e:\n",
    "        logging.warning(f\"PNG ìƒì„± ì‹¤íŒ¨({blob_name} p{page_num+1} t{idx}): {e}\")\n",
    "        png_ok = False\n",
    "\n",
    "    # MD ìƒì„± (í•´ë‹¹ í‘œë§Œ)\n",
    "    try:\n",
    "        md_text = t.to_markdown()\n",
    "        md_path.write_text(md_text, encoding=\"utf-8\")\n",
    "        md_ok = True\n",
    "    except Exception as e:\n",
    "        logging.warning(f\"MD ìƒì„± ì‹¤íŒ¨({blob_name} p{page_num+1} t{idx}): {e}\")\n",
    "        md_ok = False\n",
    "\n",
    "    # ë‘˜ ë‹¤ ì„±ê³µì‹œì—ë§Œ ì—…ë¡œë“œ + history ë°˜ì˜\n",
    "    if png_ok and md_ok:\n",
    "        # PNG ì—…ë¡œë“œ (image ì»¨í…Œì´ë„ˆ)\n",
    "        png_bc = img_bc.container_client.get_blob_client(png_name)\n",
    "        with open(png_path, \"rb\") as f:\n",
    "            png_bc.upload_blob(\n",
    "                f,\n",
    "                overwrite=True,\n",
    "                max_concurrency=3,\n",
    "                timeout=600,\n",
    "                content_settings=ContentSettings(content_type=\"image/png\"),\n",
    "            )\n",
    "\n",
    "        # MD ì—…ë¡œë“œ (markdown ì»¨í…Œì´ë„ˆ)\n",
    "        md_blob = md_bc.container_client.get_blob_client(md_name)\n",
    "        with open(md_path, \"rb\") as f:\n",
    "            md_blob.upload_blob(\n",
    "                f,\n",
    "                overwrite=True,\n",
    "                max_concurrency=3,\n",
    "                timeout=600,\n",
    "                content_settings=ContentSettings(content_type=\"text/markdown\"),\n",
    "            )\n",
    "\n",
    "        # history.csv ì—…ë°ì´íŠ¸ (ì—†ìœ¼ë©´ ìƒì„±)\n",
    "        history_blob = \"history.csv\"\n",
    "        hist_client = hist_bc.container_client.get_blob_client(history_blob)\n",
    "\n",
    "        header = [\"original_pdf\", \"png_name\", \"md_name\", \"page\", \"category\", \"table_index\"]\n",
    "        rows = []\n",
    "        try:\n",
    "            existing = hist_client.download_blob(max_concurrency=2).readall().decode(\"utf-8\")\n",
    "            reader = csv.reader(existing.splitlines())\n",
    "            rows.extend(list(reader))\n",
    "            if not rows or rows[0] != header:\n",
    "                rows.insert(0, header)  # í—¤ë” ë³´ì •\n",
    "        except ResourceNotFoundError:\n",
    "            rows.append(header)\n",
    "\n",
    "        rows.append([blob_name, png_name, md_name, str(page_num + 1), \"meritz\", str(idx)])\n",
    "\n",
    "        # CSV ì¬ìƒì„± í›„ ì—…ë¡œë“œ(ë®ì–´ì“°ê¸°)\n",
    "        byte_buf = io.BytesIO()\n",
    "        text_wr = io.TextIOWrapper(byte_buf, encoding=\"utf-8\", newline=\"\")\n",
    "        writer = csv.writer(text_wr, quoting=csv.QUOTE_ALL)\n",
    "        for r in rows:\n",
    "            writer.writerow(r)\n",
    "        text_wr.flush()\n",
    "        byte_buf.seek(0)\n",
    "\n",
    "        hist_client.upload_blob(\n",
    "            byte_buf.getvalue(),\n",
    "            overwrite=True,\n",
    "            max_concurrency=2,\n",
    "            timeout=600,\n",
    "            content_settings=ContentSettings(content_type=\"text/csv\"),\n",
    "        )\n",
    "        text_wr.close()\n",
    "        byte_buf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "pix = page.get_pixmap(dpi=300, clip=union_rect)\n",
    "pix.save(str(png_path))\n",
    "png_ok = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'write_text'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[27]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      6\u001b[39m         md_parts.append(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m> Error converting table \u001b[39m\u001b[38;5;132;01m{\u001b[39;00midx\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      7\u001b[39m md_text = \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m---\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m.join(md_parts)\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[43mmd_path\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrite_text\u001b[49m(md_text, encoding=\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      9\u001b[39m md_ok = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[31mAttributeError\u001b[39m: 'str' object has no attribute 'write_text'"
     ]
    }
   ],
   "source": [
    "md_parts = []\n",
    "for idx, t in enumerate(tables, start=1):\n",
    "    try:\n",
    "        md_parts.append(t.to_markdown())\n",
    "    except Exception as e:\n",
    "        md_parts.append(f\"> Error converting table {idx}: {e}\")\n",
    "md_text = \"\\n\\n---\\n\\n\".join(md_parts)\n",
    "md_path.write_text(md_text, encoding=\"utf-8\")\n",
    "md_ok = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'á„†á…¦á„…á…µá„á…³á„ƒá…¡á„‹á…µá„…á…¦á†¨á„á…³(á„‹á…µá†«á„á…¥á„‚á…¦á†º)á„‹á…¥á†¸á„†á…®á„‹á…­á†¼á„Œá…¡á„ƒá…©á†¼á„á…¡á„‡á…©á„’á…¥á†·á„‹á…£á†¨á„€á…ªá†«'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "170"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['á„†á…¦á„…á…µá„á…³á„ƒá…¡á„‹á…µá„…á…¦á†¨á„á…³(á„‹á…µá†«á„á…¥á„‚á…¦á†º)á„‹á…¥á†¸á„†á…®á„‹á…­á†¼á„Œá…¡á„ƒá…©á†¼á„á…¡á„‡á…©á„’á…¥á†·á„‹á…£á†¨á„€á…ªá†«.pdf']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'mkdir'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m local_pdf_path = \u001b[43mdata_bc\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdownload_to_temp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblob_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownload_dir\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 69\u001b[39m, in \u001b[36mblob_controller.download_to_temp\u001b[39m\u001b[34m(self, blob_name, tmp_dir)\u001b[39m\n\u001b[32m     65\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdownload_to_temp\u001b[39m(\u001b[38;5;28mself\u001b[39m, blob_name: \u001b[38;5;28mstr\u001b[39m, tmp_dir: Path) -> Path:\n\u001b[32m     66\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     67\u001b[39m \u001b[33;03m    blob_name(ì»¨í…Œì´ë„ˆ ë‚´ ê²½ë¡œ)ì„ tmp_dirì— íŒŒì¼ë¡œ ì €ì¥í•˜ê³  ê·¸ ê²½ë¡œ ë°˜í™˜\u001b[39;00m\n\u001b[32m     68\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m69\u001b[39m     \u001b[43mtmp_dir\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmkdir\u001b[49m(parents=\u001b[38;5;28;01mTrue\u001b[39;00m, exist_ok=\u001b[38;5;28;01mTrue\u001b[39;00m)           \n\u001b[32m     70\u001b[39m     local_path = tmp_dir / Path(blob_name).name\n\u001b[32m     72\u001b[39m     bc: BlobClient = \u001b[38;5;28mself\u001b[39m.container_client.get_blob_client(blob_name)  \n",
      "\u001b[31mAttributeError\u001b[39m: 'str' object has no attribute 'mkdir'"
     ]
    }
   ],
   "source": [
    "local_pdf_path = data_bc.download_to_temp(blob_name, download_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“‚ ë‹¤ìš´ë¡œë“œ ê²½ë¡œ: /var/folders/4v/kg2p6sjs1wz11bbmc45pqxt40000gn/T/tmpcfkbnizm/hello.txt\n",
      "ğŸ“„ íŒŒì¼ ë‚´ìš©:\n",
      " ì•ˆë…•í•˜ì„¸ìš”, ì—…ë¡œë“œ í…ŒìŠ¤íŠ¸ì…ë‹ˆë‹¤.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tempfile import TemporaryDirectory\n",
    "from pathlib import Path\n",
    "\n",
    "# choiblob ì»¨í…Œì´ë„ˆì— hello.txt ê°€ ìˆë‹¤ê³  ê°€ì •\n",
    "with TemporaryDirectory() as td:\n",
    "    path = bc.download_to_temp(\"hello.txt\", Path(td))\n",
    "    print(\"ğŸ“‚ ë‹¤ìš´ë¡œë“œ ê²½ë¡œ:\", path)\n",
    "\n",
    "    # íŒŒì¼ ë‚´ìš© ì¶œë ¥\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        content = f.read()\n",
    "    print(\"ğŸ“„ íŒŒì¼ ë‚´ìš©:\\n\", content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "blob_client: BlobClient = bc.container_client.get_blob_client(blob='pdf/hello.txt')\n",
    "\n",
    "# blob_client.download_blob(timeout=600).readall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "ResourceNotFoundError",
     "evalue": "The specified blob does not exist.\nRequestId:1bcdccde-901e-004f-2126-44fa33000000\nTime:2025-10-23T14:07:25.3906531Z\nErrorCode:BlobNotFound\nContent: <?xml version=\"1.0\" encoding=\"utf-8\"?><Error><Code>BlobNotFound</Code><Message>The specified blob does not exist.\nRequestId:1bcdccde-901e-004f-2126-44fa33000000\nTime:2025-10-23T14:07:25.3906531Z</Message></Error>",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mResourceNotFoundError\u001b[39m                     Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[28]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m blob_client: BlobClient = bc.container_client.get_blob_client(\u001b[33m\"\u001b[39m\u001b[33mpdf\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m stream = \u001b[43mblob_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdownload_blob\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m600\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mtest.txt\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mwb\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m      4\u001b[39m     f.write(stream.readall())\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/table_mag/table_dataset_pipeline/.venv/lib/python3.12/site-packages/azure/core/tracing/decorator.py:119\u001b[39m, in \u001b[36mdistributed_trace.<locals>.decorator.<locals>.wrapper_use_tracer\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    117\u001b[39m \u001b[38;5;66;03m# If tracing is disabled globally and user didn't explicitly enable it, don't trace.\u001b[39;00m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m user_enabled \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m tracing_enabled \u001b[38;5;129;01mand\u001b[39;00m user_enabled \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m--> \u001b[39m\u001b[32m119\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m func(*args, **kwargs)\n\u001b[32m    121\u001b[39m \u001b[38;5;66;03m# Merge span is parameter is set, but only if no explicit parent are passed\u001b[39;00m\n\u001b[32m    122\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m merge_span \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m passed_in_parent:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/table_mag/table_dataset_pipeline/.venv/lib/python3.12/site-packages/azure/storage/blob/_blob_client.py:779\u001b[39m, in \u001b[36mBlobClient.download_blob\u001b[39m\u001b[34m(self, offset, length, encoding, **kwargs)\u001b[39m\n\u001b[32m    761\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mCustomer provided encryption key must be used over HTTPS.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    762\u001b[39m options = _download_blob_options(\n\u001b[32m    763\u001b[39m     blob_name=\u001b[38;5;28mself\u001b[39m.blob_name,\n\u001b[32m    764\u001b[39m     container_name=\u001b[38;5;28mself\u001b[39m.container_name,\n\u001b[32m   (...)\u001b[39m\u001b[32m    777\u001b[39m     client=\u001b[38;5;28mself\u001b[39m._client,\n\u001b[32m    778\u001b[39m     **kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m779\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m StorageStreamDownloader(**options)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/table_mag/table_dataset_pipeline/.venv/lib/python3.12/site-packages/azure/storage/blob/_download.py:403\u001b[39m, in \u001b[36mStorageStreamDownloader.__init__\u001b[39m\u001b[34m(self, clients, config, start_range, end_range, validate_content, encryption_options, max_concurrency, name, container, encoding, download_cls, **kwargs)\u001b[39m\n\u001b[32m    393\u001b[39m     initial_request_end = initial_request_start + first_get_size - \u001b[32m1\u001b[39m\n\u001b[32m    395\u001b[39m \u001b[38;5;28mself\u001b[39m._initial_range, \u001b[38;5;28mself\u001b[39m._initial_offset = process_range_and_offset(\n\u001b[32m    396\u001b[39m     initial_request_start,\n\u001b[32m    397\u001b[39m     initial_request_end,\n\u001b[32m   (...)\u001b[39m\u001b[32m    400\u001b[39m     \u001b[38;5;28mself\u001b[39m._encryption_data\n\u001b[32m    401\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m403\u001b[39m \u001b[38;5;28mself\u001b[39m._response = \u001b[38;5;28mself\u001b[39m._initial_request()\n\u001b[32m    404\u001b[39m \u001b[38;5;28mself\u001b[39m.properties = cast(\u001b[33m\"\u001b[39m\u001b[33mBlobProperties\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m._response.properties)\n\u001b[32m    405\u001b[39m \u001b[38;5;28mself\u001b[39m.properties.name = \u001b[38;5;28mself\u001b[39m.name\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/table_mag/table_dataset_pipeline/.venv/lib/python3.12/site-packages/azure/storage/blob/_download.py:504\u001b[39m, in \u001b[36mStorageStreamDownloader._initial_request\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    502\u001b[39m         \u001b[38;5;28mself\u001b[39m._file_size = \u001b[32m0\u001b[39m\n\u001b[32m    503\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m504\u001b[39m         process_storage_error(error)\n\u001b[32m    506\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    507\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.size == \u001b[32m0\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/table_mag/table_dataset_pipeline/.venv/lib/python3.12/site-packages/azure/storage/blob/_shared/response_handlers.py:195\u001b[39m, in \u001b[36mprocess_storage_error\u001b[39m\u001b[34m(storage_error)\u001b[39m\n\u001b[32m    192\u001b[39m error.args = (error.message,)\n\u001b[32m    193\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    194\u001b[39m     \u001b[38;5;66;03m# `from None` prevents us from double printing the exception (suppresses generated layer error context)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m195\u001b[39m     exec(\u001b[33m\"\u001b[39m\u001b[33mraise error from None\u001b[39m\u001b[33m\"\u001b[39m)  \u001b[38;5;66;03m# pylint: disable=exec-used # nosec\u001b[39;00m\n\u001b[32m    196\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mSyntaxError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    197\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m error \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mexc\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<string>:1\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/table_mag/table_dataset_pipeline/.venv/lib/python3.12/site-packages/azure/storage/blob/_download.py:456\u001b[39m, in \u001b[36mStorageStreamDownloader._initial_request\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    454\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m retry_active:\n\u001b[32m    455\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m456\u001b[39m         location_mode, response = cast(Tuple[Optional[\u001b[38;5;28mstr\u001b[39m], Any], \u001b[38;5;28mself\u001b[39m._clients.blob.download(\n\u001b[32m    457\u001b[39m             \u001b[38;5;28mrange\u001b[39m=range_header,\n\u001b[32m    458\u001b[39m             range_get_content_md5=range_validation,\n\u001b[32m    459\u001b[39m             validate_content=\u001b[38;5;28mself\u001b[39m._validate_content,\n\u001b[32m    460\u001b[39m             data_stream_total=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    461\u001b[39m             download_stream_current=\u001b[32m0\u001b[39m,\n\u001b[32m    462\u001b[39m             **\u001b[38;5;28mself\u001b[39m._request_options\n\u001b[32m    463\u001b[39m         ))\n\u001b[32m    465\u001b[39m         \u001b[38;5;66;03m# Check the location we read from to ensure we use the same one\u001b[39;00m\n\u001b[32m    466\u001b[39m         \u001b[38;5;66;03m# for subsequent requests.\u001b[39;00m\n\u001b[32m    467\u001b[39m         \u001b[38;5;28mself\u001b[39m._location_mode = location_mode\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/table_mag/table_dataset_pipeline/.venv/lib/python3.12/site-packages/azure/core/tracing/decorator.py:119\u001b[39m, in \u001b[36mdistributed_trace.<locals>.decorator.<locals>.wrapper_use_tracer\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    117\u001b[39m \u001b[38;5;66;03m# If tracing is disabled globally and user didn't explicitly enable it, don't trace.\u001b[39;00m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m user_enabled \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m tracing_enabled \u001b[38;5;129;01mand\u001b[39;00m user_enabled \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m--> \u001b[39m\u001b[32m119\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m func(*args, **kwargs)\n\u001b[32m    121\u001b[39m \u001b[38;5;66;03m# Merge span is parameter is set, but only if no explicit parent are passed\u001b[39;00m\n\u001b[32m    122\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m merge_span \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m passed_in_parent:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/table_mag/table_dataset_pipeline/.venv/lib/python3.12/site-packages/azure/storage/blob/_generated/operations/_blob_operations.py:1650\u001b[39m, in \u001b[36mBlobOperations.download\u001b[39m\u001b[34m(self, snapshot, version_id, timeout, range, range_get_content_md5, range_get_content_crc64, structured_body_type, request_id_parameter, lease_access_conditions, cpk_info, modified_access_conditions, **kwargs)\u001b[39m\n\u001b[32m   1648\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (StreamConsumedError, StreamClosedError):\n\u001b[32m   1649\u001b[39m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1650\u001b[39m map_error(status_code=response.status_code, response=response, error_map=error_map)\n\u001b[32m   1651\u001b[39m error = \u001b[38;5;28mself\u001b[39m._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)\n\u001b[32m   1652\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m HttpResponseError(response=response, model=error)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/table_mag/table_dataset_pipeline/.venv/lib/python3.12/site-packages/azure/core/exceptions.py:163\u001b[39m, in \u001b[36mmap_error\u001b[39m\u001b[34m(status_code, response, error_map)\u001b[39m\n\u001b[32m    161\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m    162\u001b[39m error = error_type(response=response)\n\u001b[32m--> \u001b[39m\u001b[32m163\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m error\n",
      "\u001b[31mResourceNotFoundError\u001b[39m: The specified blob does not exist.\nRequestId:1bcdccde-901e-004f-2126-44fa33000000\nTime:2025-10-23T14:07:25.3906531Z\nErrorCode:BlobNotFound\nContent: <?xml version=\"1.0\" encoding=\"utf-8\"?><Error><Code>BlobNotFound</Code><Message>The specified blob does not exist.\nRequestId:1bcdccde-901e-004f-2126-44fa33000000\nTime:2025-10-23T14:07:25.3906531Z</Message></Error>"
     ]
    }
   ],
   "source": [
    "blob_client: BlobClient = bc.container_client.get_blob_client(\"pdf\")\n",
    "stream = blob_client.download_blob(timeout=600)\n",
    "with open(\"test.txt\", \"wb\") as f:\n",
    "    f.write(stream.readall())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hello.txt']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bc.list_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bc.download_to_temp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hello.txt'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.basename(\"/Users/jaehyeokchoi/Desktop/table_mag/table_dataset_pipeline/hello.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uploaded blob path (in container): hello.txt\n",
      "exists size: 47 last_modified: 2025-10-23 14:16:51+00:00\n",
      "list under prefix:\n"
     ]
    }
   ],
   "source": [
    "# ì—…ë¡œë“œ\n",
    "uploaded_path = bc.upload_pdf_to_blob(\"/Users/jaehyeokchoi/Desktop/table_mag/table_dataset_pipeline/hello.txt\")\n",
    "print(\"uploaded blob path (in container):\", uploaded_path)\n",
    "# ì˜ˆ: pdf/hello.txt\n",
    "\n",
    "# ê²€ì¦: ë°©ê¸ˆ ì˜¬ë¦° blobì˜ ì†ì„± ì½ê¸°\n",
    "props = bc.container_client.get_blob_client(uploaded_path).get_blob_properties()\n",
    "print(\"exists size:\", props.size, \"last_modified:\", props.last_modified)\n",
    "\n",
    "print(\"list under prefix:\")\n",
    "for b in bc.container_client.list_blobs(name_starts_with=\"pdf/\"):\n",
    "    print(\" -\", b.name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list under prefix:\n",
      " - pdf/hello.txt\n"
     ]
    }
   ],
   "source": [
    "print(\"list under prefix:\")\n",
    "for b in bc.container_client.list_blobs(name_starts_with=\"pdf/\"):\n",
    "    print(\" -\", b.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pdf/hello.txt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'pdf/hello.txt'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob_client.upload_pdf_to_blob(file_path=\"/Users/jaehyeokchoi/Desktop/table_mag/table_dataset_pipeline/hello.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
